dataloader:
  drop_last: false
  num_workers: 4
  persistent_workers: true
  pin_memory: true
  prefetch_factor: 6
dataset:
  dataset_path: /nfs/ap/mnt/sxtn2/chem/GEOM_data/geom_processed/grpo/train_smiles.jsonl
  smiles_mapping_path: /nfs/ap/mnt/sxtn2/chem/GEOM_data/geom_processed/grpo/train_smiles_to_pickle.json
device:
  device_type: h100
  num_gpus: 6
generation:
  do_sample: true
  max_completion_length: 2500
  num_return_sequences: 1
  repetition_penalty: 1.0
  temperature: 1.0
grpo:
  adam_beta1: 0.9
  adam_beta2: 0.95
  beta: 0
  checkpoint_base_dir: /nfs/h100/raid/chem/checkpoints/conf_grpo
  delta: 1.5
  enable_posebusters: false
  grad_acc_steps: 8
  lambda_match: 1.5
  lambda_qual: 1.0
  lambda_smcov: 0.5
  learning_rate: 2.0e-05
  max_grad_norm: 1.0
  max_ground_truths: 30
  max_steps: 8000
  num_epochs: 1
  num_generations: 16
  num_iterations: 4
  output_base_dir: ./grpo_outputs
  per_device_batch_size: 8
  r_floor: -1.0
  reward_strategy: v3
  reward_weight_match: 0.15
  reward_weight_rmsd: 0.85
  rho: 0.75
  rmsd_const: 0.75
  scheduler: cosine
  seed: 1
  sigma: 0.3
  temperature: 1.0
  warmup_ratio: 0.15
  weight_decay: 0.1
model:
  checkpoint_path: /nfs/h100/raid/chem/checkpoints/yerevann/qwen3_06b/251210-1955-d79f-qwen3_06b_pre_4e_144effb/step-80000-hf/
  conf_tags:
  - '[CONFORMER]'
  - '[/CONFORMER]'
  dtype: bf16
  mol_tags:
  - '[SMILES]'
  - '[/SMILES]'
  pad_token: <|finetune_right_pad_id|>
  tokenizer_path: /auto/home/menuab/code/3DMolGen/src/molgen3D/training/tokenizers/Qwen3_tokenizer_custom
processing:
  eos_token_id: 151672
run:
  log_level: INFO
  name: qwen3_v3_reward_geom_aligned
trainer:
  attn_implementation: flash_attention_2
  log_on_each_node: false
  logging_steps: 1
  loss_type: grpo
  save_on_each_node: false
  save_safetensors: true
  save_steps: 1000
  save_strategy: steps
  save_total_limit: 8
  torch_dtype: bfloat16
  use_liger_loss: true
