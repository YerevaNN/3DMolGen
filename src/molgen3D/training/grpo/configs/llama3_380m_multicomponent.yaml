dataloader:
  drop_last: false
  num_workers: 4
  persistent_workers: true
  pin_memory: true
  prefetch_factor: 6
dataset:
  dataset_path: /nfs/ap/home/_menuab_/cartesianisomeric/grpo/train_data_full.jsonl
  smiles_mapping_path: /nfs/ap/mnt/sxtn2/chem/GEOM_data/smiles_mapping.json
device:
  device_type: a100
  num_gpus: 2
generation:
  do_sample: true
  max_completion_length: 1000
  num_return_sequences: 1
  repetition_penalty: 1.0
  temperature: 1.0
grpo:
  adam_beta1: 0.9
  adam_beta2: 0.95
  advanced_reward:
    coverage_scale: 0.6
    delta: 0.75
    diversity_scale: 1.2
    enable_diversity: true
    enable_posebusters: true
    match_partial_credit: false
    max_reference_conformers: 30
    normalization_epsilon: 1.0e-06
    posebusters_config: mol
    precision_scale: 0.45
    weights:
      coverage: 0.35
      diversity: 0.05
      match: 0.15
      precision: 0.35
      validity: 0.25
  beta: 0
  checkpoint_base_dir: /nfs/h100/raid/chem/checkpoints/conf_grpo
  checkpoint_dir: /nfs/h100/raid/chem/checkpoints/conf_grpo/2025-10-01-12:00_380m_mc_reward
  grad_acc_steps: 8
  learning_rate: 1.0e-05
  max_grad_norm: 1.0
  max_ground_truths: 64
  max_steps: 16000
  num_epochs: 1
  num_generations: 16
  num_iterations: 4
  output_base_dir: ./grpo_outputs
  output_dir: /auto/home/menuab/code/3DMolGen/grpo_outputs/2025-10-01-12:00_380m_mc_reward
  per_device_batch_size: 16
  reward_strategy: multi_component
  reward_weight_match: 0.15
  reward_weight_rmsd: 0.85
  rmsd_const: 0.75
  scheduler: cosine
  seed: 1
  temperature: 1.0
  warmup_ratio: 0.15
  weight_decay: 0.1
model:
  checkpoint_path: /nfs/h100/raid/chem/checkpoints/hf/yerevann/Llama-3.2-380M_conformers/e184d4d867804fbd8a8c45bf/step-30000/
  conf_tags:
  - '[CONFORMER]'
  - '[/CONFORMER]'
  dtype: bf16
  mol_tags:
  - '[SMILES]'
  - '[/SMILES]'
  pad_token: <|finetune_right_pad_id|>
  tokenizer_path: /auto/home/menuab/code/YNNtitan/torchtitan/tokenizers/Llama-3.2-chem-1B-v1
processing:
  eos_token_id: 128329
run:
  log_level: INFO
  name: 380m_mc_reward_lr2e-5_32bs_4ksteps
trainer:
  attn_implementation: flash_attention_2
  log_on_each_node: false
  logging_steps: 1
  loss_type: grpo
  save_on_each_node: false
  save_safetensors: true
  save_steps: 1000
  save_strategy: 'no'
  save_total_limit: 8
  torch_dtype: bfloat16
  use_liger_loss: true
