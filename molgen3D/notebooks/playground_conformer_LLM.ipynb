{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "import rdkit\n",
    "import re\n",
    "from rdkit import Chem\n",
    "from posebusters import PoseBusters\n",
    "import json\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "# This enables inline rendering of molecules\n",
    "IPythonConsole.ipython_useSVG=True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "!export PYTHONPATH=$PYTHONPATH:/auto/home/menuab/code/3DMolGen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'molgen3D'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m project_root \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m sys\u001b[38;5;241m.\u001b[39mpath:\n\u001b[1;32m      9\u001b[0m     sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39minsert(\u001b[38;5;241m0\u001b[39m, project_root)\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mmolgen3D\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata_processing_utils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m decode_cartesian_raw\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'molgen3D'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Get the absolute path to the project root\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\"))  # Assuming notebook is one level deep inside the project\n",
    "\n",
    "# Add the project root to sys.path\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "\n",
    "from molgen3D.utils.data_processing_utils import decode_cartesian_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.float32, device(type='cuda', index=1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cart_1x_path = \"/nfs/h100/raid/chem/checkpoints/hf/yerevann/Llama-3.2-1B_conformers/c037e75255bc41c19c716939/step-4500\"\n",
    "cart_2x_path = \"/nfs/h100/raid/chem/checkpoints/hf/yerevann/Llama-3.2-1B_conformers/d267db61f57d4b428baa604a/step-9000\"\n",
    "cart_4x_path = \"/nfs/h100/raid/chem/checkpoints/hf/yerevann/Llama-3.2-1B_conformers/3408e9758572478c80393771/step-18000\"\n",
    "cart_6e_path = \"/nfs/h100/raid/chem/checkpoints/hf/yerevann/Llama-3.2-1B_conformers/301b8328481243c6aa8d8003/step-27000\"\n",
    "cart_8e_path = \"/nfs/h100/raid/chem/checkpoints/hf/yerevann/Llama-3.2-1B_conformers/c13311b27056459eaccf5877/step-36000\"\n",
    "m100_100 = \"/nfs/h100/raid/chem/checkpoints/hf/yerevann/Llama-3.2-27M_conformers/afebcc510dec403f9532dff6/step-42600\"\n",
    "m100_120p_path = \"/nfs/h100/raid/chem/checkpoints/hf/yerevann/Llama-3.2-100M_conformers/c29bd453f4ff497d8c99c8f7/step-30000\"\n",
    "\n",
    "\n",
    "tokenizer  = AutoTokenizer.from_pretrained(\"/auto/home/menuab/code/YNNtitan/torchtitan/tokenizers/Llama-3.2-chem-1B-v1\", padding_side='left')\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "model = AutoModelForCausalLM.from_pretrained(m100_120p_path, \n",
    "                                             torch_dtype=torch.float32).to(\"cuda:1\")\n",
    "model.generation_config.pad_token_id = tokenizer.pad_token_id\n",
    "model.dtype, model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import transformers\n",
    "top_p_sampling_config = transformers.GenerationConfig (\n",
    "  do_sample=True,\n",
    "  temperature=0.8,\n",
    "  top_p=0.9\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|begin_of_text|>[SMILES][H][C]([H])=[C]([H])[C]([H])([H])[O][C](=[O])[C]([H])([H])[C]([H])([H])[C](=[O])[N]([H])[c]1[c]([H])[c]([H])[c]([H])[c]2[c]([H])[c]([H])[c]([H])[c]([H])[c]12[/SMILES][CONFORMER][H<-3.4386,-1.7210,2.7221>][C<-3.2844,-1.6904,1.6540>]([H<-3.9768,-2.2526,1.0446>])=[C<-2.3256,-0.9643,1.1130>]([H<-1.6615,-0.3755,1.7304>])[C<-2.0398,-0.8939,-0.3566>]([H<-2.6273,-1.6212,-0.9206>])([H<-0.9747,-1.0575,-0.5448>])[O<-2.4109,0.3883,-0.8830>][C<-3.6528,0.8059,-0.6420>](=[O<-4.4766,0.2068,-0.0088>])[C<-3.8874,2.1477,-1.3157>]([H<-3.4205,2.1118,-2.2959>])([H<-4.9655,2.3122,-1.4156>])[C<-3.2508,3.2557,-0.4629>]([H<-3.8272,3.3847,0.4453>])([H<-3.2398,4.1897,-1.0307>])[C<-1.8350,2.8642,-0.0636>](=[O<-1.1587,3.5253,0.6875>])[N<-1.4476,1.6842,-0.6270>]([H<-2.1489,1.2179,-1.1938>])[c<-0.3155,0.9195,-0.3070>]1[c<0.8377,1.4874,0.1927>]([H<0.8690,2.5432,0.4100>])[c<1.9694,0.7016,0.4472>]([H<2.8538,1.1747,0.8530>])[c<1.9469,-0.6365,0.1855>]([H<2.8059,-1.2632,0.4102>])[c<0.8033,-1.2407,-0.3870>]2[c<0.7838,-2.6245,-0.6670>]([H<1.6460,-3.2150,-0.3699>])[c<-0.2869,-3.1980,-1.3072>]([H<-0.2948,-4.2574,-1.5289>])[c<-1.3652,-2.4074,-1.7305>]([H<-2.1865,-2.8573,-2.2725>])[c<-1.3777,-1.0815,-1.4237>]([H<-2.2139,-0.4788,-1.7645>])[c<-0.3216,-0.4896,-0.6798>]12[/CONFORMER]\n",
      "[H][C]([H])=[C]([H])[C]([H])([H])[O][C](=[O])[C]([H])([H])[C]([H])([H])[C](=[O])[N]([H])[c]1[c]([H])[c]([H])[c]([H])[c]2[c]([H])[c]([H])[c]([H])[c]([H])[c]12\n",
      "[H][C]([H])=[C]([H])[C]([H])([H])[O][C](=[O])[C]([H])([H])[C]([H])([H])[C](=[O])[N]([H])[c]1[c]([H])[c]([H])[c]([H])[c]2[c]([H])[c]([H])[c]([H])[c]([H])[c]12\n"
     ]
    }
   ],
   "source": [
    "canonical_smiles = '[H][C]([H])=[C]([H])[C]([H])([H])[O][C](=[O])[C]([H])([H])[C]([H])([H])[C](=[O])[N]([H])[c]1[c]([H])[c]([H])[c]([H])[c]2[c]([H])[c]([H])[c]([H])[c]([H])[c]12'\n",
    "pad_len = 0\n",
    "prompt = f\"[SMILES]{canonical_smiles}[/SMILES]\"\n",
    "prompt = tokenizer(prompt, \n",
    "                   padding='max_length', \n",
    "                   max_length=len(tokenizer(prompt)[\"input_ids\"])+pad_len, \n",
    "                   return_tensors=\"pt\", \n",
    "                   add_special_tokens=True).to(model.device)\n",
    "output = model.generate(input_ids=prompt[\"input_ids\"], \n",
    "                        attention_mask=prompt[\"attention_mask\"], \n",
    "                        max_new_tokens=2000, \n",
    "                        eos_token_id=128329, \n",
    "                        generation_config=top_p_sampling_config)\n",
    "output = tokenizer.batch_decode(output)[0]\n",
    "generated_conformer = output[output.find(\"[CONFORMER]\")+len(\"[CONFORMER]\"):output.find(\"[/CONFORMER]\")]\n",
    "generated_smiles = re.sub(r'<[^>]*>', '', generated_conformer) \n",
    "print(output)\n",
    "print(canonical_smiles)\n",
    "print(generated_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mol num: 1 generating 138 conformers for C#CCNC(=O)C1=C[C@@H](c2ccc(Br)cc2)C[C@@H](OCc2ccc(CO)cc2)O1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:None for open-end generation.\n",
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "  0%|          | 0/1000 [00:11<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len prompt toks: 88, len gen toks: 602\n",
      "canonical_smiles='[H][O][C]1=[C]([C](=[N][C]([H])([H])[C]([H])([H])[c]2[c]([H])[c]([H])[c]([H])[c]([H])[c]2[H])[C]([H])([H])[H])[C](=[O])[S][C]1([H])[H]'\n",
      "generated_smiles='[H][O][C]1=[C]([C](=[N][C]([H])([H])[C]([H])([H])[c]2[c]([H])[c]([H])[c]([H])[c]([H])[c]2[H])[C]([H])([H])[H])[C](=[O])[S][C]1([H])[H]'\n",
      "out='<|begin_of_text|>[SMILES][H][O][C]1=[C]([C](=[N][C]([H])([H])[C]([H])([H])[c]2[c]([H])[c]([H])[c]([H])[c]([H])[c]2[H])[C]([H])([H])[H])[C](=[O])[S][C]1([H])[H][/SMILES][CONFORMER][H<-2.1227,-2.4066,0.0171>][O<-3.0615,-2.0513,0.0322>][C<-2.9815,-0.7348,0.0014>]1=[C<-1.9039,0.0974,-0.0384>]([C<-0.5432,-0.4122,-0.0478>](=[N<0.4296,0.4126,-0.1234>][C<1.8135,0.0420,-0.1334>]([H<1.9969,-0.8204,-0.7864>])([H<2.1302,-0.2397,0.8801>])[C<2.6484,1.2332,-0.6214>]([H<2.4324,1.4031,-1.6782>])([H<2.3361,2.1208,-0.0685>])[c<4.1106,0.9633,-0.4145>]2[c<4.7994,0.1287,-1.2863>]([H<4.2861,-0.2955,-2.1375>])[c<6.1366,-0.1581,-1.0765>]([H<6.6606,-0.8065,-1.7634>])[c<6.8020,0.3871,0.0090>]([H<7.8449,0.1654,0.1731>])[c<6.1239,1.2187,0.8845>]([H<6.6377,1.6476,1.7330>])[c<4.7856,1.5018,0.6741>]2[H<4.2601,2.1502,1.3614>])[C<-0.4104,-1.9117,0.0210>]([H<-0.9299,-2.3644,-0.8224>])([H<-0.8524,-2.2782,0.9457>])[H<0.6333,-2.2106,-0.0072>])[C<-2.2627,1.5013,-0.0491>](=[O<-1.5613,2.4783,-0.0843>])[S<-4.0578,1.6688,0.0138>][C<-4.3463,-0.1338,0.0368>]1([H<-4.9504,-0.4087,0.9003>])[H<-4.8792,-0.4277,-0.8686>][/CONFORMER]'\n",
      "canonical_smiles='[H][O][C]1=[C]([C](=[N][C]([H])([H])[C]([H])([H])[c]2[c]([H])[c]([H])[c]([H])[c]([H])[c]2[H])[C]([H])([H])[H])[C](=[O])[S][C]1([H])[H]'\n",
      "generated_smiles='[H][O][C]1=[C]([C](=[N][C]([H])([H])[C]([H])([H])[c]2[c]([H])[c]([H])[c]([H])[c]([H])[c]2[H])[C]([H])([H])[H])[C](=[O])[S][C]1([H])[H]'\n",
      "out='<|begin_of_text|>[SMILES][H][O][C]1=[C]([C](=[N][C]([H])([H])[C]([H])([H])[c]2[c]([H])[c]([H])[c]([H])[c]([H])[c]2[H])[C]([H])([H])[H])[C](=[O])[S][C]1([H])[H][/SMILES][CONFORMER][H<-0.0428,-2.0534,0.0136>][O<0.8586,-2.4756,-0.1021>][C<1.7541,-1.5045,-0.1013>]1=[C<1.5205,-0.1622,-0.0390>]([C<0.1827,0.3908,0.0235>](=[N<-0.7948,-0.4501,0.0219>][C<-2.1902,-0.1317,0.0688>]([H<-2.4402,0.4017,0.9957>])([H<-2.4724,0.5118,-0.7743>])[C<-2.9914,-1.4411,0.0036>]([H<-2.7085,-2.0659,0.8520>])([H<-2.7197,-1.9700,-0.9106>])[c<-4.4629,-1.1422,0.0278>]2[c<-5.1443,-1.0433,1.2329>]([H<-4.6184,-1.2250,2.1598>])[c<-6.4899,-0.7202,1.2569>]([H<-7.0089,-0.6495,2.2009>])[c<-7.1699,-0.4892,0.0729>]([H<-8.2197,-0.2382,0.0920>])[c<-6.4979,-0.5834,-1.1341>]([H<-7.0235,-0.4052,-2.0605>])[c<-5.1524,-0.9041,-1.1561>]2[H<-4.6303,-0.9767,-2.0993>])[C<0.0272,1.8851,0.0939>]([H<-1.0234,2.1637,0.0915>])([H<0.4977,2.3612,-0.7652>])[H<0.5184,2.2633,0.9884>])[C<2.7306,0.6582,-0.0649>](=[O<2.8362,1.8534,-0.0334>])[S<4.1699,-0.4166,-0.1774>][C<3.1846,-1.9454,-0.1988>]1([H<3.4264,-2.5255,0.6919>])[H<3.4214,-2.5393,-1.0805>][/CONFORMER]'\n",
      "----------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# file = open('drugs_test_mols_inference.jsonl','w') \n",
    "ref, gen, incs = [], [], []\n",
    "inc = 0\n",
    "import re\n",
    "for en, mol_dict in enumerate(tqdm(test_mols)):\n",
    "    canonical_smiles = mol_dict[\"canonical_smiles\"]\n",
    "    canonical_smiles = '[H][O][C]1=[C]([C](=[N][C]([H])([H])[C]([H])([H])[c]2[c]([H])[c]([H])[c]([H])[c]([H])[c]2[H])[C]([H])([H])[H])[C](=[O])[S][C]1([H])[H]'\n",
    "\n",
    "    geom_smiles = mol_dict[\"geom_smiles\"]\n",
    "    num_generations = mol_dict[\"num_confs\"] * 2\n",
    "    print(f\"mol num: {en+1} generating {num_generations} conformers for {geom_smiles}\")    \n",
    "    generations = []\n",
    "    prompt = f\"[SMILES]{canonical_smiles}[/SMILES]\"\n",
    "    prompt = tokenizer(prompt, return_tensors=\"pt\", add_special_tokens=True).to(model.device).input_ids\n",
    "    \n",
    "    # output = model.generate(prompt, max_new_tokens=2000, eos_token_id=128329, do_sample=False)\n",
    "    output = model.generate(prompt, max_length=2000, eos_token_id=128329, \n",
    "                        # num_beams=10,\n",
    "                        # num_beam_groups=2,\n",
    "                        # diversity_penalty=1.1,\n",
    "                        num_return_sequences=2, \n",
    "                        do_sample=True,\n",
    "                        top_p=0.90,\n",
    "                        temperature=0.8,\n",
    "                        # top_k=3\n",
    "                        )\n",
    "    print(f\"len prompt toks: {len(prompt[0])}, len gen toks: {len(output[0])-len(prompt[0])}\")\n",
    "    output = tokenizer.batch_decode(output)\n",
    "    # print(\"raw output: \", output)\n",
    "    # print(\"canonical_smiles: \", canonical_smiles)\n",
    "    # display(Chem.MolFromSmiles(canonical_smiles))\n",
    "    for out in output:\n",
    "        generated_conformer = out[out.find(\"[CONFORMER]\")+len(\"[CONFORMER]\"):out.find(\"[/CONFORMER]\")]\n",
    "        # print(generated_conformer)\n",
    "        generated_smiles = re.sub(r'<[^>]*>', '', generated_conformer)\n",
    "        if generated_smiles == canonical_smiles:\n",
    "            ref.append(geom_smiles)\n",
    "            gen.append(generated_smiles)\n",
    "            print(f\"{canonical_smiles=}\")\n",
    "            print(f\"{generated_smiles=}\")\n",
    "            print(f\"{out=}\")\n",
    "            sample = {\n",
    "                \"geom_smiles\": geom_smiles,\n",
    "                \"generated_conformer\": generated_conformer\n",
    "            }\n",
    "            file.write(f\"{json.dumps(sample)}\\n\")\n",
    "        else:\n",
    "            print(\"smiles didn't match for \")\n",
    "            print(f\"{canonical_smiles=}\")\n",
    "            print(f\"{generated_smiles=}\")\n",
    "            print(out)\n",
    "            incs.append(out)\n",
    "            inc += 1\n",
    "        # print(\"generated_smiles: \", generated_smiles)\n",
    "        # display(Chem.MolFromSmiles(generated_smiles))\n",
    "    print('----------------------')\n",
    "    file.close()\n",
    "    break\n",
    "    # if en==100:\n",
    "    #     break\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_gen = '[H<-0.0541,-1.9089,0.0001>][O<-0.9993,-2.2537,0.0001>][C<-1.7999,-1.2063,0.0001>]1=[C<-1.4564,0.1106,0.0001>]([C<-0.0788,0.5689,0.0001>](=[N<0.8417,-0.3277,0.0001>][C<2.2485,-0.0474,0.0001>]([H<2.5225,0.5473,0.8810>])([H<2.5319,0.5279,-0.8907>])[C<3.0100,-1.3801,0.0118>]([H<2.7208,-1.9349,0.9052>])([H<2.7059,-1.9615,-0.8595>])[c<4.4899,-1.1329,0.0004>]2[c<5.2423,-1.3378,1.1489>]([H<4.7600,-1.7082,2.0424>])[c<6.6015,-1.0774,1.1557>]([H<7.1753,-1.2451,2.0552>])[c<7.2245,-0.6015,0.0147>]([H<8.2852,-0.3985,0.0200>])[c<6.4818,-0.3901,-1.1344>]([H<6.9632,-0.0206,-2.0281>])[c<5.1237,-0.6519,-1.1403>]2[H<4.5471,-0.4887,-2.0396>])[C<0.1665,2.0521,-0.0001>]([H<1.2285,2.2721,-0.0001>])([H<-0.2910,2.4999,-0.8815>])[H<-0.2959,2.5005,0.8790>])[C<-2.6091,1.0094,0.0001>](=[O<-2.6401,2.2087,0.0001>])[S<-4.1199,0.0224,-0.0001>][C<-3.2319,-1.5780,-0.0001>]1([H<-3.5528,-2.1773,-0.8520>])[H<-3.4629,-2.1250,0.9149>]'"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titan",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
